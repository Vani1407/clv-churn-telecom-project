{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "982e9634-ece5-480d-8a5a-cfc181f59636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "98ec13e1-d5ad-426e-bad4-33558ff65704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aec66950-c6bb-4744-88e1-78753c864c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, roc_auc_score,\n",
    "                             roc_curve, mean_squared_error, r2_score)\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2caa574-66b4-42e5-9d38-aa3ce0d6a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Configuration ---------------------------\n",
    "DATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"   # change if your file is elsewhere \n",
    "OUTPUT_DIR = \"telco_project_output\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d27b6f5c-e3a4-4a09-840e-cb676922841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Helper Functions ---------------------------\n",
    "def save_fig(fig, name):\n",
    "    path = os.path.join(OUTPUT_DIR, name)\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c86d3592-1486-478f-a09c-ccbac2827378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "Loaded data shape: (7043, 21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 1. Load Data ---------------------------\n",
    "print(\"Loading data from:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded data shape:\", df.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "33cd72b8-b920-4bb4-960a-efe079976a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column before drop:\n",
      " customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n",
      "Shape after dropping NA: (7043, 21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 2. Basic Cleaning ---------------------------\n",
    "# Convert TotalCharges to numeric (there are spaces for customers with zero tenure)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Fill or drop missing TotalCharges - if tenure==0 then TotalCharges is NaN -> set to 0\n",
    "df.loc[(df['tenure'] == 0) & (df['TotalCharges'].isna()), 'TotalCharges'] = 0.0\n",
    "\n",
    "# Print missing values summary\n",
    "print(\"Missing values per column before drop:\\n\", df.isna().sum())\n",
    "# Drop any remaining missing rows (should be minimal)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(\"Shape after dropping NA:\", df.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "500fe711-b56b-4de4-9d64-01bb8d0476c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn distribution:\n",
      " Churn\n",
      "No     5174\n",
      "Yes    1869\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 3. Quick EDA (prints + basic plots saved) ---------------------------\n",
    "# Churn distribution\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "print(\"Churn distribution:\\n\", churn_counts)\n",
    "print()\n",
    "\n",
    "# Plot churn count\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='Churn')\n",
    "plt.title('Churn Distribution')\n",
    "save_fig(fig, 'churn_distribution.png')\n",
    "\n",
    "# MonthlyCharges distribution\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['MonthlyCharges'], bins=30, kde=True)\n",
    "plt.title('Monthly Charges Distribution')\n",
    "save_fig(fig, 'monthlycharges_dist.png')\n",
    "\n",
    "# Tenure distribution\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['tenure'], bins=30, kde=True)\n",
    "plt.title('Tenure Distribution')\n",
    "save_fig(fig, 'tenure_dist.png')\n",
    "\n",
    "# Correlation heatmap for numeric columns\n",
    "num_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\", cmap='Blues')\n",
    "plt.title('Numeric Feature Correlations')\n",
    "save_fig(fig, 'numeric_correlations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c42248f0-e48b-4b9f-80d4-9439cc69ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved engineered dataset to: telco_project_output\\telco_engineered.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 4. Feature Engineering ---------------------------\n",
    "# Create CLV proxy: CLV = MonthlyCharges * tenure  (simple approach)\n",
    "df['CLV'] = df['MonthlyCharges'] * df['tenure']\n",
    "\n",
    "# Average revenue per month (handle tenure==0)\n",
    "df['AvgRevPerMonth'] = df.apply(lambda r: r['TotalCharges']/r['tenure'] if r['tenure']>0 else r['MonthlyCharges'], axis=1)\n",
    "\n",
    "# Tenure groups\n",
    "def tenure_group(t):\n",
    "    if t == 0:\n",
    "        return '0'\n",
    "    elif t <= 12:\n",
    "        return '0-12'\n",
    "    elif t <= 24:\n",
    "        return '13-24'\n",
    "    elif t <= 48:\n",
    "        return '25-48'\n",
    "    elif t <= 60:\n",
    "        return '49-60'\n",
    "    else:\n",
    "        return '60+'\n",
    "df['TenureGroup'] = df['tenure'].apply(tenure_group)\n",
    "\n",
    "# Binary encode 'Churn' target\n",
    "df['ChurnFlag'] = df['Churn'].map({'Yes':1, 'No':0})\n",
    "\n",
    "# Simplify PaymentMethod categories if too many\n",
    "df['PaymentMethodSimple'] = df['PaymentMethod'].replace({\n",
    "    'Bank transfer (automatic)':'BankTransfer',\n",
    "    'Credit card (automatic)':'CreditCard',\n",
    "    'Electronic check':'ElectronicCheck',\n",
    "    'Mailed check':'MailedCheck'\n",
    "})\n",
    "\n",
    "# Drop customerID - not useful for modeling\n",
    "if 'customerID' in df.columns:\n",
    "    df_model = df.drop(columns=['customerID'])\n",
    "else:\n",
    "    df_model = df.copy()\n",
    "\n",
    "# Save engineered dataset\n",
    "engineered_csv = os.path.join(OUTPUT_DIR, 'telco_engineered.csv')\n",
    "df_model.to_csv(engineered_csv, index=False)\n",
    "print(\"Saved engineered dataset to:\", engineered_csv)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47a67876-55cd-4c24-8fd7-178b9544112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- 5. Prepare Data for Modeling ---------------------------\n",
    "# Select features to use (mix of numerical and categorical)\n",
    "num_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'CLV', 'AvgRevPerMonth']\n",
    "cat_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethodSimple', 'TenureGroup']\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "06d558d7-7489-42c7-80a0-0c9291389314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CLV regression pipeline.\n",
      "CLV Regression RMSE: 15.9151\n",
      "CLV Regression R2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load saved CLV regression model --------------------\n",
    "clv_regressor_path = os.path.join(OUTPUT_DIR, 'clv_regressor.joblib')\n",
    "clv_regressor = joblib.load(clv_regressor_path)\n",
    "print(\"Loaded CLV regression pipeline.\")\n",
    "\n",
    "# Now you can make predictions\n",
    "reg_preds = clv_regressor.predict(Xr_test)\n",
    "reg_rmse = rmse(yr_test, reg_preds)\n",
    "reg_r2 = r2_score(yr_test, reg_preds)\n",
    "print(f\"CLV Regression RMSE: {reg_rmse:.4f}\")\n",
    "print(f\"CLV Regression R2: {reg_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "302db45e-5983-4fb8-b9dd-5df44b7fc240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- CLV Regression Modeling -----\n",
      "\n",
      "Train/Test shapes (regression): (5634, 22) (1409, 22)\n",
      "CLV Regression RMSE: 15.9151\n",
      "CLV Regression R2: 1.0000\n",
      "Saved CLV regression pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 6A. CLV Regression ---------------------------\n",
    "print(\"\\n----- CLV Regression Modeling -----\\n\")\n",
    "X_reg = df_model[num_features + cat_features]\n",
    "y_reg = df_model['CLV']\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(\"Train/Test shapes (regression):\", Xr_train.shape, Xr_test.shape)\n",
    "\n",
    "reg_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Fit regression model\n",
    "reg_pipeline.fit(Xr_train, yr_train)\n",
    "reg_preds = reg_pipeline.predict(Xr_test)\n",
    "reg_rmse = rmse(yr_test, reg_preds)\n",
    "reg_r2 = r2_score(yr_test, reg_preds)\n",
    "print(f\"CLV Regression RMSE: {reg_rmse:.4f}\")\n",
    "print(f\"CLV Regression R2: {reg_r2:.4f}\")\n",
    "\n",
    "# Save regression model\n",
    "joblib.dump(reg_pipeline, os.path.join(OUTPUT_DIR, 'clv_regressor.joblib'))\n",
    "print(\"Saved CLV regression pipeline.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7be21594-a157-4cc6-b88e-cdb77046b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Churn classification pipeline.\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Load saved Churn classifier model --------------------\n",
    "churn_classifier_path = os.path.join(OUTPUT_DIR, 'churn_classifier.joblib')\n",
    "clf_pipeline = joblib.load(churn_classifier_path)\n",
    "print(\"Loaded Churn classification pipeline.\")\n",
    "\n",
    "# Now you can make predictions\n",
    "clf_preds = clf_pipeline.predict(Xc_test)\n",
    "clf_probs = clf_pipeline.predict_proba(Xc_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "16b79e26-c249-4465-b96c-70e9b5612e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Churn Classification Modeling -----\n",
      "\n",
      "Train/Test shapes (classification): (5634, 22) (1409, 22)\n",
      "Churn Classification Accuracy: 0.7871\n",
      "Churn Classification AUC: 0.8261\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1035\n",
      "           1       0.63      0.48      0.55       374\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.73      0.69      0.70      1409\n",
      "weighted avg       0.77      0.79      0.78      1409\n",
      "\n",
      "Confusion Matrix:\n",
      " [[928 107]\n",
      " [193 181]]\n",
      "Saved churn classification pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 6B. Churn Classification ---------------------------\n",
    "print(\"\\n----- Churn Classification Modeling -----\\n\")\n",
    "X_clf = df_model[num_features + cat_features]\n",
    "y_clf = df_model['ChurnFlag']\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_clf, y_clf, test_size=0.2, stratify=y_clf, random_state=RANDOM_STATE)\n",
    "print(\"Train/Test shapes (classification):\", Xc_train.shape, Xc_test.shape)\n",
    "\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Fit classifier\n",
    "clf_pipeline.fit(Xc_train, yc_train)\n",
    "clf_preds = clf_pipeline.predict(Xc_test)\n",
    "clf_probs = clf_pipeline.predict_proba(Xc_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(yc_test, clf_preds)\n",
    "auc = roc_auc_score(yc_test, clf_probs)\n",
    "print(f\"Churn Classification Accuracy: {acc:.4f}\")\n",
    "print(f\"Churn Classification AUC: {auc:.4f}\")\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\\n\", classification_report(yc_test, clf_preds))\n",
    "cm = confusion_matrix(yc_test, clf_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Save classifier\n",
    "joblib.dump(clf_pipeline, os.path.join(OUTPUT_DIR, 'churn_classifier.joblib'))\n",
    "print(\"Saved churn classification pipeline.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8c672b0-8433-4ffb-b959-2e5699f52c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved top feature importances to CSV: telco_project_output\\feature_importances_top25.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 7. Feature Importance (from RandomForest) ---------------------------\n",
    "# Extract feature names after preprocessing (one-hot encoding)\n",
    "ohe = clf_pipeline.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot']\n",
    "ohe_features = ohe.get_feature_names_out(cat_features)\n",
    "feature_names = np.concatenate([num_features, ohe_features])\n",
    "\n",
    "rf_model = clf_pipeline.named_steps['model']\n",
    "importances = rf_model.feature_importances_\n",
    "feat_imp = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(25)\n",
    "feat_imp_csv = os.path.join(OUTPUT_DIR, 'feature_importances_top25.csv')\n",
    "feat_imp.to_csv(feat_imp_csv, index=False)\n",
    "print(\"Saved top feature importances to CSV:\", feat_imp_csv)\n",
    "\n",
    "# Plot top features\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "sns.barplot(data=feat_imp, x='importance', y='feature')\n",
    "plt.title('Top 25 Feature Importances (Churn RF)')\n",
    "save_fig(fig, 'feature_importances_top25.png')\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c0b04e43-1866-4de7-b838-f36e9fd63d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- 8. Model Evaluation - More Metrics ---------------------------\n",
    "# ROC Curve plot\n",
    "fpr, tpr, thresholds = roc_curve(yc_test, clf_probs)\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Churn Classifier')\n",
    "plt.legend()\n",
    "save_fig(fig, 'roc_curve_churn.png')\n",
    "\n",
    "# Residuals plot CLV regression\n",
    "residuals = yr_test - reg_preds\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.scatter(reg_preds, residuals, alpha=0.4)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted CLV')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('CLV Regression Residuals')\n",
    "save_fig(fig, 'clv_residuals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "801a3ac6-fc24-466c-8a38-c7e343271202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved business insights file: telco_project_output\\business_insights.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 9. Business Insights & Sample Policy ---------------------------\n",
    "insights = [\n",
    "    \"High monthly charges + low tenure -> elevated churn risk. Prioritize these for retention offers.\",\n",
    "    \"Customers on month-to-month contracts churn more. Offer discounted annual/one-year bundles to reduce churn.\",\n",
    "    \"Auto-pay (BankTransfer/CreditCard) customers show lower churn; incentivize electronic payments.\",\n",
    "    \"Segment customers by predicted CLV to create tiered retention budgets (High CLV -> VIP retention).\",\n",
    "    \"Use predicted churn probability to drive intervention prioritization (top X% get immediate offers).\"\n",
    "]\n",
    "insights_path = os.path.join(OUTPUT_DIR, 'business_insights.txt')\n",
    "with open(insights_path, 'w') as f:\n",
    "    f.write('\\n'.join(insights))\n",
    "print(\"Saved business insights file:\", insights_path)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c43f7cf8-bced-491c-9730-dba8f158b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary metrics to JSON: telco_project_output\\summary_metrics.json\n",
      "\n",
      "All outputs (models, figures, CSVs, and summary) saved in: telco_project_output\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 10. Save outputs summary ---------------------------\n",
    "summary = {\n",
    "    'rows': int(df.shape[0]),\n",
    "    'clv_rmse': float(reg_rmse),\n",
    "    'clv_r2': float(reg_r2),\n",
    "    'churn_accuracy': float(acc),\n",
    "    'churn_auc': float(auc),\n",
    "    'models_saved': ['clv_regressor.joblib', 'churn_classifier.joblib']\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(OUTPUT_DIR, 'summary_metrics.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved summary metrics to JSON:\", summary_path)\n",
    "print()\n",
    "\n",
    "print('All outputs (models, figures, CSVs, and summary) saved in:', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7574580-9598-4a82-bb2a-f5731dcd57cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70944f04-579c-4cbf-b77c-77b815879aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
